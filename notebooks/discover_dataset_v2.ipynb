{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from collections import Counter\n",
    "import json\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path('/datasets/nia/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 클리닝\n",
    "### Remove unneccessary files which start with \".\"\n",
    "### 라벨링데이터 디렉토리에 \"._.DS_Store\" 파일과 \"._폴더명\" 파일이 존재함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제될 파일 수 0\n"
     ]
    }
   ],
   "source": [
    "files_to_remove = list(dataset_dir.rglob('.*'))\n",
    "print('삭제될 파일 수', len(files_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제완료 0\n"
     ]
    }
   ],
   "source": [
    "for p in files_to_remove:\n",
    "    p.unlink()\n",
    "print('삭제완료', len(files_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일명 기반 탐색\n",
    "## 학습시 최하단 2-depth 까지만 확인\n",
    "### ex) **/lidar/\\*.json, **/thermal/\\*.json, **/image_\\*/\\*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_path = list(dataset_dir.rglob('*.json'))\n",
    "annotations_filenames_set = {p.name for p in annotations_path}\n",
    "annotations_filenames_list = [p.name for p in annotations_path]\n",
    "len(annotations_filenames_list) - len(annotations_filenames_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 같은 파일이름을 가진 경우, 내용이 같은지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_counter = Counter(annotations_filenames_list)\n",
    "duplicated_filenames = [\n",
    "    filename\n",
    "    for filename, count in filename_counter.items()\n",
    "    if count > 1\n",
    "]\n",
    "len(duplicated_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_same_annotations(file_paths):\n",
    "    paths = [Path(p) for p in file_paths]\n",
    "\n",
    "    anns = []\n",
    "    for p in paths:\n",
    "        with open(p, 'r') as fp:\n",
    "            ann = json.load(fp)\n",
    "        anns.append(ann)\n",
    "    \n",
    "    return all([ann == anns[0] for ann in anns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_filename_paths = [list(dataset_dir.rglob(filename)) for filename in duplicated_filenames]\n",
    "all([have_same_annotations(file_paths) for file_paths in duplicated_filename_paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path의 어느 부분에 차이가 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- /datasets/nia/231018/annotations/230913_4/230913_181405_K/230913_181405_K(1)/Annotation/LK_A06_R05_erh_rainy_01020891.json\n",
      "?                                                                              ^^^^^ ^^^^\n",
      "\n",
      "+ /datasets/nia/231018/annotations/230913_4/230913_181405_K/230913_181405_K(1)/lidar/LK_A06_R05_erh_rainy_01020891.json\n",
      "?                                                                              ^^^ ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = duplicated_filename_paths[0]\n",
    "print('\\n'.join(difflib.ndiff([str(p1)], [str(p2)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([str(p1).replace('Annotation', 'lidar') == str(p2)\n",
    "     for p1, p2 in duplicated_filename_paths])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구조 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 볼륨 확인 (전달받은 데이터 날짜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'231018', '230927'}\n"
     ]
    }
   ],
   "source": [
    "volume_paths = sorted(list(dataset_dir.iterdir()))\n",
    "volume_names = {p.name for p in volume_paths}\n",
    "print(volume_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_dirs = {p.name: p / 'collections' for p in volume_paths}\n",
    "annotations_dirs = {p.name: p / 'annotations' for p in volume_paths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확장자 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_suffixes(directory):\n",
    "    suffixes = set()\n",
    "    for p in Path(directory).rglob('*'):\n",
    "        if len(p.suffix) > 0:\n",
    "            suffixes.add(p.suffix)\n",
    "    return suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_suffixes = {volume: sorted(get_all_suffixes(collections_dir)) for volume, collections_dir in collections_dirs.items()}\n",
    "annotations_suffixes = {volume: sorted(get_all_suffixes(annotations_dir)) for volume, annotations_dir in annotations_dirs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>230927</th><th>231018</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;.csv&quot;</td><td>&quot;.csv&quot;</td></tr><tr><td>&quot;.pcd&quot;</td><td>&quot;.pcd&quot;</td></tr><tr><td>&quot;.png&quot;</td><td>&quot;.png&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────┐\n",
       "│ 230927 ┆ 231018 │\n",
       "│ ---    ┆ ---    │\n",
       "│ str    ┆ str    │\n",
       "╞════════╪════════╡\n",
       "│ .csv   ┆ .csv   │\n",
       "│ .pcd   ┆ .pcd   │\n",
       "│ .png   ┆ .png   │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(collections_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>230927</th><th>231018</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;.json&quot;</td><td>&quot;.json&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌────────┬────────┐\n",
       "│ 230927 ┆ 231018 │\n",
       "│ ---    ┆ ---    │\n",
       "│ str    ┆ str    │\n",
       "╞════════╪════════╡\n",
       "│ .json  ┆ .json  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(annotations_suffixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 채널 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_channels(directory):\n",
    "    channels = set()\n",
    "    for p in Path(directory).rglob('*.*'):\n",
    "        channels.add(p.parts[-2])\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_channels = {volume: sorted(get_all_channels(collections_dir)) for volume, collections_dir in collections_dirs.items()}\n",
    "annotations_channels = {volume: sorted(get_all_channels(annotations_dir)) for volume, annotations_dir in annotations_dirs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>230927</th><th>231018</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;gps&quot;</td><td>&quot;gps&quot;</td></tr><tr><td>&quot;image_B&quot;</td><td>&quot;image_B&quot;</td></tr><tr><td>&quot;image_F&quot;</td><td>&quot;image_F&quot;</td></tr><tr><td>&quot;image_L&quot;</td><td>&quot;image_L&quot;</td></tr><tr><td>&quot;image_R&quot;</td><td>&quot;image_R&quot;</td></tr><tr><td>&quot;lidar&quot;</td><td>&quot;lidar&quot;</td></tr><tr><td>&quot;thermal&quot;</td><td>&quot;thermal&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌─────────┬─────────┐\n",
       "│ 230927  ┆ 231018  │\n",
       "│ ---     ┆ ---     │\n",
       "│ str     ┆ str     │\n",
       "╞═════════╪═════════╡\n",
       "│ gps     ┆ gps     │\n",
       "│ image_B ┆ image_B │\n",
       "│ image_F ┆ image_F │\n",
       "│ image_L ┆ image_L │\n",
       "│ image_R ┆ image_R │\n",
       "│ lidar   ┆ lidar   │\n",
       "│ thermal ┆ thermal │\n",
       "└─────────┴─────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(collections_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>230927</th><th>231018</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;imageCaption&quot;</td><td>&quot;Annotation&quot;</td></tr><tr><td>&quot;image_B&quot;</td><td>&quot;image_B&quot;</td></tr><tr><td>&quot;image_F&quot;</td><td>&quot;image_F&quot;</td></tr><tr><td>&quot;image_L&quot;</td><td>&quot;image_L&quot;</td></tr><tr><td>&quot;image_R&quot;</td><td>&quot;image_R&quot;</td></tr><tr><td>&quot;lidar&quot;</td><td>&quot;lidar&quot;</td></tr><tr><td>&quot;thermal&quot;</td><td>&quot;thermal&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌──────────────┬────────────┐\n",
       "│ 230927       ┆ 231018     │\n",
       "│ ---          ┆ ---        │\n",
       "│ str          ┆ str        │\n",
       "╞══════════════╪════════════╡\n",
       "│ imageCaption ┆ Annotation │\n",
       "│ image_B      ┆ image_B    │\n",
       "│ image_F      ┆ image_F    │\n",
       "│ image_L      ┆ image_L    │\n",
       "│ image_R      ┆ image_R    │\n",
       "│ lidar        ┆ lidar      │\n",
       "│ thermal      ┆ thermal    │\n",
       "└──────────────┴────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(annotations_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 디렉토리 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_dataset_dir = '/datasets/nia'\n",
    "\n",
    "volume_values = ['230927', '231018']\n",
    "type_values = ['annotations', 'collections']\n",
    "channel_values = ['lidar', 'thermal', 'image_F', 'image_L', 'image_R', 'image_B']\n",
    "\n",
    "pattern = (\n",
    "    rf\"{nia_dataset_dir}\"\n",
    "    rf\"/(?P<volume>{'|'.join(volume_values)})\"\n",
    "    rf\"/(?P<type>{'|'.join(type_values)})\"\n",
    "    rf\"/.*?/\"\n",
    "    rf\"(?P<channel>{'|'.join(channel_values)})\"\n",
    "    rf\"/(?P<filename>[^/]+\\..+)$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = pl.Series('full_path', map(str, Path(nia_dataset_dir).rglob('*.*')))\n",
    "df_extracted = file_paths.str.extract_groups(pattern).struct.unnest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_extracted.with_columns([\n",
    "    pl.col('volume').cast(pl.Categorical).cat.set_ordering('lexical'),\n",
    "    pl.col('type').cast(pl.Categorical).cat.set_ordering('lexical'),\n",
    "    pl.col('channel').cast(pl.Categorical).cat.set_ordering('lexical'),\n",
    "    file_paths,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 채널별 이미지, 레이블 데이터 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>channel</th><th>count</th></tr><tr><td>cat</td><td>u32</td></tr></thead><tbody><tr><td>&quot;image_B&quot;</td><td>11886</td></tr><tr><td>&quot;image_F&quot;</td><td>11886</td></tr><tr><td>&quot;image_L&quot;</td><td>11886</td></tr><tr><td>&quot;image_R&quot;</td><td>11886</td></tr><tr><td>&quot;lidar&quot;</td><td>11886</td></tr><tr><td>&quot;thermal&quot;</td><td>11886</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 2)\n",
       "┌─────────┬───────┐\n",
       "│ channel ┆ count │\n",
       "│ ---     ┆ ---   │\n",
       "│ cat     ┆ u32   │\n",
       "╞═════════╪═══════╡\n",
       "│ image_B ┆ 11886 │\n",
       "│ image_F ┆ 11886 │\n",
       "│ image_L ┆ 11886 │\n",
       "│ image_R ┆ 11886 │\n",
       "│ lidar   ┆ 11886 │\n",
       "│ thermal ┆ 11886 │\n",
       "└─────────┴───────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\n",
    "    pl.col('volume') == '230927',\n",
    "    pl.col('type') == 'collections',\n",
    ").group_by('channel').count().sort('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>volume</th><th>channel</th><th>collections</th><th>annotations</th></tr><tr><td>cat</td><td>cat</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>&quot;230927&quot;</td><td>&quot;image_B&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;230927&quot;</td><td>&quot;image_F&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;230927&quot;</td><td>&quot;image_L&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;230927&quot;</td><td>&quot;image_R&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;230927&quot;</td><td>&quot;lidar&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;230927&quot;</td><td>&quot;thermal&quot;</td><td>11886</td><td>11730</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;image_B&quot;</td><td>6207</td><td>5759</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;image_F&quot;</td><td>6141</td><td>5759</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;image_L&quot;</td><td>6007</td><td>5759</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;image_R&quot;</td><td>6007</td><td>5759</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;lidar&quot;</td><td>6007</td><td>6357</td></tr><tr><td>&quot;231018&quot;</td><td>&quot;thermal&quot;</td><td>6007</td><td>5970</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 4)\n",
       "┌────────┬─────────┬─────────────┬─────────────┐\n",
       "│ volume ┆ channel ┆ collections ┆ annotations │\n",
       "│ ---    ┆ ---     ┆ ---         ┆ ---         │\n",
       "│ cat    ┆ cat     ┆ u32         ┆ u32         │\n",
       "╞════════╪═════════╪═════════════╪═════════════╡\n",
       "│ 230927 ┆ image_B ┆ 11886       ┆ 11730       │\n",
       "│ 230927 ┆ image_F ┆ 11886       ┆ 11730       │\n",
       "│ 230927 ┆ image_L ┆ 11886       ┆ 11730       │\n",
       "│ 230927 ┆ image_R ┆ 11886       ┆ 11730       │\n",
       "│ …      ┆ …       ┆ …           ┆ …           │\n",
       "│ 231018 ┆ image_L ┆ 6007        ┆ 5759        │\n",
       "│ 231018 ┆ image_R ┆ 6007        ┆ 5759        │\n",
       "│ 231018 ┆ lidar   ┆ 6007        ┆ 6357        │\n",
       "│ 231018 ┆ thermal ┆ 6007        ┆ 5970        │\n",
       "└────────┴─────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_nulls().group_by(['volume', 'channel']).agg(\n",
    "    pl.col('filename').filter(pl.col('type') == 'collections').count().alias('collections'),\n",
    "    pl.col('filename').filter(pl.col('type') == 'annotations').count().alias('annotations'),\n",
    ").sort('volume', 'channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = df.drop_nulls().with_columns(\n",
    "    pl.col('filename').str.split('.').list.first().alias('stem'),\n",
    ").group_by('stem').agg(\n",
    "    pl.col('volume').first(),\n",
    "    pl.col('channel').first(),\n",
    "    pl.col('full_path').filter(pl.col('type') == 'collections').first().alias('collection_path'),\n",
    "    pl.col('full_path').filter(pl.col('type') == 'annotations').first().alias('annotation_path'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unmatched = df_aggregated.filter(\n",
    "    pl.any_horizontal(\n",
    "        pl.col('collection_path').is_null(),\n",
    "        pl.col('annotation_path').is_null(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "df_matched = df_aggregated.filter(\n",
    "    pl.all_horizontal(\n",
    "        pl.col('collection_path').is_not_null(),\n",
    "        pl.col('annotation_path').is_not_null(),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (82_978, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>stem</th><th>volume</th><th>channel</th><th>collection_path</th><th>annotation_path</th></tr><tr><td>str</td><td>cat</td><td>cat</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;LK_B01_R04_aft…</td><td>&quot;230927&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A14_R01_aft…</td><td>&quot;231018&quot;</td><td>&quot;image_L&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A04_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A09_R03_aft…</td><td>&quot;231018&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;TK_B09_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;thermal&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A04_R03_erh…</td><td>&quot;231018&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_B13_R03_aft…</td><td>&quot;230927&quot;</td><td>&quot;image_B&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A03_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A03_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;image_R&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A06_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_B02_R01_erh…</td><td>&quot;230927&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A07_R01_aft…</td><td>&quot;231018&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;CK_B02_R05_erh…</td><td>&quot;231018&quot;</td><td>&quot;image_R&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_B08_R04_aft…</td><td>&quot;230927&quot;</td><td>&quot;image_R&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A09_R01_erh…</td><td>&quot;230927&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A14_R01_aft…</td><td>&quot;231018&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A13_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_B09_R03_aft…</td><td>&quot;230927&quot;</td><td>&quot;image_B&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;LK_A14_R03_aft…</td><td>&quot;231018&quot;</td><td>&quot;lidar&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;TK_A14_R04_erh…</td><td>&quot;230927&quot;</td><td>&quot;thermal&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;TK_A01_R03_aft…</td><td>&quot;231018&quot;</td><td>&quot;thermal&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_B09_R05_erh…</td><td>&quot;231018&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_A05_R01_aft…</td><td>&quot;231018&quot;</td><td>&quot;image_R&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr><tr><td>&quot;CK_B08_R04_aft…</td><td>&quot;230927&quot;</td><td>&quot;image_F&quot;</td><td>&quot;/datasets/nia/…</td><td>&quot;/datasets/nia/…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (82_978, 5)\n",
       "┌──────────────────────────┬────────┬─────────┬──────────────────────────┬─────────────────────────┐\n",
       "│ stem                     ┆ volume ┆ channel ┆ collection_path          ┆ annotation_path         │\n",
       "│ ---                      ┆ ---    ┆ ---     ┆ ---                      ┆ ---                     │\n",
       "│ str                      ┆ cat    ┆ cat     ┆ str                      ┆ str                     │\n",
       "╞══════════════════════════╪════════╪═════════╪══════════════════════════╪═════════════════════════╡\n",
       "│ LK_B01_R04_afterschool_c ┆ 230927 ┆ lidar   ┆ /datasets/nia/230927/col ┆ /datasets/nia/230927/an │\n",
       "│ lear_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ CK_A14_R01_afterschool_r ┆ 231018 ┆ image_L ┆ /datasets/nia/231018/col ┆ /datasets/nia/231018/an │\n",
       "│ ainy_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ CK_A04_R04_erh_rainy_010 ┆ 230927 ┆ image_F ┆ /datasets/nia/230927/col ┆ /datasets/nia/230927/an │\n",
       "│ 08009_F                  ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ LK_A09_R03_afterschool_r ┆ 231018 ┆ lidar   ┆ /datasets/nia/231018/col ┆ /datasets/nia/231018/an │\n",
       "│ ainy_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ …                        ┆ …      ┆ …       ┆ …                        ┆ …                       │\n",
       "│ TK_A01_R03_afterschool_r ┆ 231018 ┆ thermal ┆ /datasets/nia/231018/col ┆ /datasets/nia/231018/an │\n",
       "│ ainy_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ CK_B09_R05_erh_rainy_010 ┆ 231018 ┆ image_F ┆ /datasets/nia/231018/col ┆ /datasets/nia/231018/an │\n",
       "│ 20627_F                  ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ CK_A05_R01_afterschool_r ┆ 231018 ┆ image_R ┆ /datasets/nia/231018/col ┆ /datasets/nia/231018/an │\n",
       "│ ainy_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "│ CK_B08_R04_afterschool_c ┆ 230927 ┆ image_F ┆ /datasets/nia/230927/col ┆ /datasets/nia/230927/an │\n",
       "│ lear_010…                ┆        ┆         ┆ lections…                ┆ notations…              │\n",
       "└──────────────────────────┴────────┴─────────┴──────────────────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matched"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
